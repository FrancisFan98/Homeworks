{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on CARAVAN dataset with different feature selection techniques\n",
    "    Author : Francis Fan\n",
    "    Date : 02/29/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview \n",
    "    As the volumn of data explosively grows in modern society, people are becoming more incapable of handling these data themselves. Instead, people developed a bunch of useful tools on computer to help them understand the data. One of the most prevalent tool for analyzing data is Linear Regression model. \n",
    "    However, with only Linear Regression model, there are still many problems that might cause inaccurate result. One of the most common defect is the curse of dimensionality which is caused by overwhelming features and results in overfitting your data. \n",
    "    Today, we are going to use linear regression model on a caravan data set with different feature selection techniques to try to understand the underlying meaning of the dataset. We will perform an EDA first to see the overall relationships between factors and use linear regression with different feature selection methods to verify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# feature selection using LassoCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# forward/backward feature selection based on p-value\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# feature selection based on low variance\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import os  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "    This data set used in the CoIL 2000 Challenge contains information on customers of an insurance company. The data consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. https://www.kaggle.com/uciml/caravan-insurance-challenge/home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('caravan-insurance-challenge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis \n",
    "    Since we are trying to understand the hidden relationships and correlations under the dataset, it is quite helpful for us to take a EDA on the dataset and have a good look of what might be going on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to look at is the dimensions of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 87)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 9822 records of diabetes patient. Each record has 87 elements, 86 variables and 1 result(CARAVAN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether there is null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset turns out to be quite clean without any missing value. I guess it is preprocessed by professional people and then uploaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>...</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "      <th>CARAVAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.00000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>24.253207</td>\n",
       "      <td>1.108735</td>\n",
       "      <td>2.677561</td>\n",
       "      <td>2.996437</td>\n",
       "      <td>5.779067</td>\n",
       "      <td>0.700672</td>\n",
       "      <td>4.637650</td>\n",
       "      <td>1.050092</td>\n",
       "      <td>3.262981</td>\n",
       "      <td>6.188964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.004276</td>\n",
       "      <td>0.574018</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.03146</td>\n",
       "      <td>0.008450</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.059662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>12.918058</td>\n",
       "      <td>0.412101</td>\n",
       "      <td>0.780701</td>\n",
       "      <td>0.804660</td>\n",
       "      <td>2.874148</td>\n",
       "      <td>1.015107</td>\n",
       "      <td>1.721212</td>\n",
       "      <td>1.011156</td>\n",
       "      <td>1.606287</td>\n",
       "      <td>1.896070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067535</td>\n",
       "      <td>0.088764</td>\n",
       "      <td>0.071224</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.077996</td>\n",
       "      <td>0.20907</td>\n",
       "      <td>0.092647</td>\n",
       "      <td>0.117728</td>\n",
       "      <td>0.236872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           MOSTYPE     MAANTHUI      MGEMOMV     MGEMLEEF     MOSHOOFD  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean     24.253207     1.108735     2.677561     2.996437     5.779067   \n",
       "std      12.918058     0.412101     0.780701     0.804660     2.874148   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%      10.000000     1.000000     2.000000     2.000000     3.000000   \n",
       "50%      30.000000     1.000000     3.000000     3.000000     7.000000   \n",
       "75%      35.000000     1.000000     3.000000     3.000000     8.000000   \n",
       "max      41.000000    10.000000     6.000000     6.000000    10.000000   \n",
       "\n",
       "            MGODRK       MGODPR       MGODOV       MGODGE       MRELGE  ...  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000  ...   \n",
       "mean      0.700672     4.637650     1.050092     3.262981     6.188964  ...   \n",
       "std       1.015107     1.721212     1.011156     1.606287     1.896070  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     4.000000     0.000000     2.000000     5.000000  ...   \n",
       "50%       0.000000     5.000000     1.000000     3.000000     6.000000  ...   \n",
       "75%       1.000000     6.000000     2.000000     4.000000     7.000000  ...   \n",
       "max       9.000000     9.000000     5.000000     9.000000     9.000000  ...   \n",
       "\n",
       "          APERSONG      AGEZONG      AWAOREG       ABRAND      AZEILPL  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.004582     0.007941     0.004276     0.574018     0.000916   \n",
       "std       0.067535     0.088764     0.071224     0.561255     0.030258   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     2.000000     7.000000     1.000000   \n",
       "\n",
       "          APLEZIER      AFIETS      AINBOED     ABYSTAND      CARAVAN  \n",
       "count  9822.000000  9822.00000  9822.000000  9822.000000  9822.000000  \n",
       "mean      0.005091     0.03146     0.008450     0.013846     0.059662  \n",
       "std       0.077996     0.20907     0.092647     0.117728     0.236872  \n",
       "min       0.000000     0.00000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.00000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.00000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.00000     0.000000     0.000000     0.000000  \n",
       "max       2.000000     4.00000     2.000000     2.000000     1.000000  \n",
       "\n",
       "[8 rows x 86 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a histogram of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMRElEQVR4nO3cf6jd9X3H8edryWzXjlatt6VLwmJp6GYHoxLUrbA/mqFRx+IfFTLGGkog/7itG4NN90+graAw5lZYhdBkS0upFVcwzDIJahmD1Rpr6aqZJGhn7nT1lkT3o7Rduvf+uJ/Ya7k399x577nR9/MB4Z7v5/v5nvv5/pHn+fK955xUFZKkHn5qvRcgSZoeoy9JjRh9SWrE6EtSI0ZfkhrZuN4LOJ/LLrustm7dut7LkKTXlccff/y7VTWz2L4LOvpbt27l2LFj670MSXpdSfKvS+3z9o4kNWL0JakRoy9JjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEaMviQ1ckF/Ive12nrrA+u9hAvSt++4cb2XIGmdeKUvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDUyUfST/GGSJ5N8K8kXkrw5yeVJHk1yIskXk1w05r5pbJ8c+7cueJ7bxvjTSa5bm1OSJC1l2egn2QT8PrC9qn4J2ADsBu4E7qqqbcAZYO84ZC9wpqreC9w15pHkinHc+4GdwKeTbFjd05Eknc+kt3c2Aj+TZCPwFuAF4EPAfWP/YeCm8XjX2Gbs35EkY/yeqvpBVT0LnASueu2nIEma1LLRr6p/A/4MeI752L8MPA68VFVnx7RZYNN4vAk4NY49O+a/Y+H4Ise8Ism+JMeSHJubm/v/nJMkaQmT3N65hPmr9MuBnwPeCly/yNQ6d8gS+5Yaf/VA1YGq2l5V22dmZpZbniRpBSa5vfPrwLNVNVdV/wN8CfhV4OJxuwdgM/D8eDwLbAEY+98OnF44vsgxkqQpmCT6zwHXJHnLuDe/A3gKeAT48JizB7h/PD4ythn7H66qGuO7x7t7Lge2AV9bndOQJE1i43ITqurRJPcBXwfOAk8AB4AHgHuSfHKMHRyHHAQ+l+Qk81f4u8fzPJnkXuZfMM4Ct1TVj1b5fCRJ57Fs9AGqaj+w/yeGn2GRd99U1feBm5d4ntuB21e4RknSKvETuZLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDVi9CWpkYmin+TiJPcl+Zckx5P8SpJLkxxNcmL8vGTMTZJPJTmZ5JtJrlzwPHvG/BNJ9qzVSUmSFjfplf5fAn9fVb8A/DJwHLgVeKiqtgEPjW2A64Ft498+4G6AJJcC+4GrgauA/edeKCRJ07Fs9JO8Dfg14CBAVf2wql4CdgGHx7TDwE3j8S7gszXvq8DFSd4NXAccrarTVXUGOArsXNWzkSSd1yRX+u8B5oC/TvJEks8keSvwrqp6AWD8fOeYvwk4teD42TG21PirJNmX5FiSY3Nzcys+IUnS0iaJ/kbgSuDuqvoA8N/8+FbOYrLIWJ1n/NUDVQeqantVbZ+ZmZlgeZKkSU0S/VlgtqoeHdv3Mf8i8J1x24bx88UF87csOH4z8Px5xiVJU7Js9Kvq34FTSd43hnYATwFHgHPvwNkD3D8eHwE+Mt7Fcw3w8rj98yBwbZJLxh9wrx1jkqQp2TjhvN8DPp/kIuAZ4KPMv2Dcm2Qv8Bxw85j7ZeAG4CTwvTGXqjqd5BPAY2Pex6vq9KqchSRpIhNFv6q+AWxfZNeOReYWcMsSz3MIOLSSBUqSVo+fyJWkRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjUwc/SQbkjyR5O/G9uVJHk1yIskXk1w0xt80tk+O/VsXPMdtY/zpJNet9slIks5vJVf6HwOOL9i+E7irqrYBZ4C9Y3wvcKaq3gvcNeaR5ApgN/B+YCfw6SQbXtvyJUkrMVH0k2wGbgQ+M7YDfAi4b0w5DNw0Hu8a24z9O8b8XcA9VfWDqnoWOAlctRonIUmazKRX+n8B/DHwv2P7HcBLVXV2bM8Cm8bjTcApgLH/5TH/lfFFjnlFkn1JjiU5Njc3t4JTkSQtZ9noJ/kN4MWqenzh8CJTa5l95zvmxwNVB6pqe1Vtn5mZWW55kqQV2DjBnA8Cv5nkBuDNwNuYv/K/OMnGcTW/GXh+zJ8FtgCzSTYCbwdOLxg/Z+ExkqQpWPZKv6puq6rNVbWV+T/EPlxVvw08Anx4TNsD3D8eHxnbjP0PV1WN8d3j3T2XA9uAr63amUiSljXJlf5S/gS4J8kngSeAg2P8IPC5JCeZv8LfDVBVTya5F3gKOAvcUlU/eg2/X5K0QiuKflV9BfjKePwMi7z7pqq+D9y8xPG3A7evdJGSpNXhJ3IlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiPLRj/JliSPJDme5MkkHxvjlyY5muTE+HnJGE+STyU5meSbSa5c8Fx7xvwTSfas3WlJkhYzyZX+WeCPquoXgWuAW5JcAdwKPFRV24CHxjbA9cC28W8fcDfMv0gA+4GrgauA/edeKCRJ07Fs9Kvqhar6+nj8n8BxYBOwCzg8ph0GbhqPdwGfrXlfBS5O8m7gOuBoVZ2uqjPAUWDnqp6NJOm8VnRPP8lW4APAo8C7quoFmH9hAN45pm0CTi04bHaMLTX+k79jX5JjSY7Nzc2tZHmSpGVMHP0kPwv8LfAHVfUf55u6yFidZ/zVA1UHqmp7VW2fmZmZdHmSpAlMFP0kP8188D9fVV8aw98Zt20YP18c47PAlgWHbwaeP8+4JGlKJnn3ToCDwPGq+vMFu44A596Bswe4f8H4R8a7eK4BXh63fx4Erk1yyfgD7rVjTJI0JRsnmPNB4HeAf07yjTH2p8AdwL1J9gLPATePfV8GbgBOAt8DPgpQVaeTfAJ4bMz7eFWdXpWzkCRNZNnoV9U/svj9eIAdi8wv4JYlnusQcGglC5QkrR4/kStJjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjRh9SWpk43ovQFJvW299YL2XcEH69h03rsnzeqUvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjUw9+kl2Jnk6yckkt07790tSZ1ONfpINwF8B1wNXAL+V5IpprkGSOpv2lf5VwMmqeqaqfgjcA+ya8hokqa1pf+HaJuDUgu1Z4OqFE5LsA/aNzf9K8vSU1rbWLgO+u96LAMid670C6YL1Rvl/+vNL7Zh29LPIWL1qo+oAcGA6y5meJMeqavt6r0PS0jr8P5327Z1ZYMuC7c3A81NegyS1Ne3oPwZsS3J5kouA3cCRKa9Bktqa6u2dqjqb5HeBB4ENwKGqenKaa1hHb7hbVtIb0Bv+/2mqavlZkqQ3BD+RK0mNGH1JasTorzG/dkK68CU5lOTFJN9a77WsNaO/hvzaCel142+Aneu9iGkw+mvLr52QXgeq6h+A0+u9jmkw+mtrsa+d2LROa5Eko7/Glv3aCUmaJqO/tvzaCUkXFKO/tvzaCUkXFKO/hqrqLHDuayeOA/c2+toJ6XUjyReAfwLel2Q2yd71XtNa8WsYJKkRr/QlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRv4POBPN4/FRYToAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [\"0\", \"1\"]\n",
    "height = [9822 - sum(df.CARAVAN), sum(df.CARAVAN)]\n",
    "plt.bar(x = x, height = height, width = .3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the bar plot above, we can see that this data set is skewed. There are much more record with CARAVAN as 0 compared to CARAVAN as 1. Due to the lack of data on CARAVAN as 1, it is possible that we get inaccurate result. I will try to fit the model with the original data and fit the model with data corrected by sampling methods so that we can have a look of the difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "    The next step is to understand the dataset is to build some models and put the data in so that we can have a look about how can a computer interpret the data. For this assignment, I will use the linear regression model to find the underlying correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to look at four different models with different techniques: \n",
    "    1. Logistic regression with all features (base model)\n",
    "    2. Logistic regression with stepwise selection based on p-values\n",
    "    3. Random Forest based on Principal component analysis feature selection\n",
    "    4. Random Forest based on feature importance feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic regression with all features (base model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = df.drop(['ORIGIN'], axis=1)\n",
    "y = df_n.CARAVAN\n",
    "X = df_n.drop(\"CARAVAN\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.940643453471798"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of this model is seemingly high. However, it is quite faulty if we take a look at how many records are predicted as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 1s is : 586 in dataset, the number of 1s is :13 in predicted values\n"
     ]
    }
   ],
   "source": [
    "num_of_ones_predicted = sum(clf.predict(X))\n",
    "\n",
    "num_of_ones = sum(y)\n",
    "print(\"The number of 1s is : %d in dataset, the number of 1s is :%d in predicted values\" % (num_of_ones, num_of_ones_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this model did an awful job at recognizing a record as 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Logistic regression with stepwise selection based on p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  PPERSAUT                       with p-value 2.14684e-42\n",
      "Add  MKOOPKLA                       with p-value 1.36739e-21\n",
      "Add  PWAPART                        with p-value 3.66711e-15\n",
      "Add  APLEZIER                       with p-value 8.20766e-15\n",
      "Add  MOPLHOOG                       with p-value 4.25236e-06\n",
      "Add  PBRAND                         with p-value 3.92829e-06\n",
      "Add  MBERBOER                       with p-value 8.31838e-06\n",
      "Add  MRELGE                         with p-value 1.41977e-05\n",
      "Add  PWALAND                        with p-value 0.000361295\n",
      "Add  ABRAND                         with p-value 0.000937601\n",
      "Add  AZEILPL                        with p-value 0.00153041\n",
      "Add  MINK123M                       with p-value 0.00152554\n",
      "Add  PBYSTAND                       with p-value 0.00243579\n",
      "resulting features:\n",
      "['PPERSAUT', 'MKOOPKLA', 'PWAPART', 'APLEZIER', 'MOPLHOOG', 'PBRAND', 'MBERBOER', 'MRELGE', 'PWALAND', 'ABRAND', 'AZEILPL', 'MINK123M', 'PBYSTAND']\n"
     ]
    }
   ],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.004, \n",
    "                       threshold_out = 0.004, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "#            best_feature = new_pval.argmin()\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "result = stepwise_selection(X, y)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running stepwise_selection on the original data, we can find the features that have a p-value indicating that it it possible important to predict the target. With threshold_in as 0.04 and threshold_out as 0.04, I am able to find 13 variables that contribute more to predicting the target. Then we can train the model with these important variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stepwise_selected = df[result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9402362044390145"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_stepwise_selected, y)\n",
    "\n",
    "clf.score(X_stepwise_selected, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 1s is : 586 in dataset, the number of 1s is :5 in predicted values\n"
     ]
    }
   ],
   "source": [
    "num_of_ones_predicted = sum(clf.predict(X_stepwise_selected))\n",
    "\n",
    "num_of_ones = sum(y)\n",
    "print(\"The number of 1s is : %d in dataset, the number of 1s is :%d in predicted values\" % (num_of_ones, num_of_ones_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is even worse because it only predicted 5 records to be 1 while there are 586 1s in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Random Forest based on Principal component analysis feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9403380166972104"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "clf.fit(X_pca, y)\n",
    "\n",
    "clf.score(X_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 1s is : 586 in dataset, the number of 1s is :0 in predicted values\n"
     ]
    }
   ],
   "source": [
    "num_of_ones_predicted = sum(clf.predict(X_pca))\n",
    "\n",
    "num_of_ones = sum(y)\n",
    "print(\"The number of 1s is : %d in dataset, the number of 1s is :%d in predicted values\" % (num_of_ones, num_of_ones_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is even performing worse since It recognize no record as 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Random Forest based on feature importance feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To utilize the feature importance of each feature, we can put all the feature into a random forest model and then find the coefficient of each variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9822, 17)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With feature importance technique, we can reduce the number of features down to 17 and then let's feed it into a new random forest model and see what the results are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9403380166972104"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "clf.fit(X_new, y)\n",
    "\n",
    "clf.score(X_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 1s is : 586 in dataset, the number of 1s is :0 in predicted values\n"
     ]
    }
   ],
   "source": [
    "num_of_ones_predicted = sum(clf.predict(X_new))\n",
    "\n",
    "num_of_ones = sum(y)\n",
    "print(\"The number of 1s is : %d in dataset, the number of 1s is :%d in predicted values\" % (num_of_ones, num_of_ones_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these four models did a good job on recognizing 0s. But when it comes to 1s, they all did an awful job. I suppose this problem is caused by the skewed property of target variable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
