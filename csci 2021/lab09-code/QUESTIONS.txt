			   __________________

			    LAB 09 QUESTIONS
			   __________________


- Name: (FILL THIS in)
- NetID: (THE kauf0095 IN kauf0095@umn.edu)

Answer the questions below according to the lab specification. Write
your answers directly in this text file and submit it to complete the
lab.


Compiling and Timing
====================

  IMPORTANT: Use the provided Makefile to compile as in
  ,----
  | > make
  | gcc -Wall -g -Og -c superscalar_main.c          
  | gcc -Wall -g -Og -c superscalar_funcs.c         
  | gcc -Wall -g -Og -o superscalar_main superscalar_main.o superscalar_funcs.o
  `----
  The compilation uses `-Og' (debug level optimization) which is
  necessary to stop the compiler from modifying some loops.

  This will produce the `superscalar_main' program which has the
  following usage:
  ,----
  | > ./superscalar_main
  | usage: ./superscalar_main <ALG> <MULT> <EXP>
  |   <MULT> and <ALG> are integers, iterates for MULT * 2^{EXP} iterations
  |   <ALG> is one of
  | 	  add1_sep : add 1 times in loop
  | 	  add2_sep : add 2 times in same loop; separate destinations
  | 	  add3_sep : add 3 times in same loop; separate destinations
  | 	 add2_same : add 2 times in same loop; same destinations
  | 	  mul1_sep : multiply 1 times in loop
  | 	  mul2_sep : multiply 2 times in same loop; separate destinations
  | 	  mul3_sep : multiply 3 times in same loop; separate destinations
  | 	 mul2_same : multiply 2 times in same loop; same destinations
  |    add_and_mul_sep : add and multiply in the same loop; separate destinations
  |   add_and_mul_same : add and multiply in the same loop; same destination 
  |   add_then_mul_sep : add and multiply in different loops; separate destinations
  |  add_then_mul_same : add and multiply in different loops; same destinations
  `----

  Experiment with algorithm `add1_sep' and parameters `MULT' and `EXP'
  which control the number of iterations run. Experiment until you get a
  run time of about 1 second such as MULT=18 and EXP=27 on Vole.
  ,----
  | vole-01> time ./superscalar_main add1_sep 18 27
  | add1_sep for 18 * 2^{27} = 2415919104 iterations... complete
  | 
  | real    0m1.071s
  | user    0m1.040s
  | sys     0m0.008s
  `----


PROBLEM 1: Addition
===================

(A) add1_sep / add2_sep / add3_sep
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Examine the source code in `superscalar_funcs.c' for the following
  algorithms.
  - add1_sep : add 1 times in loop
  - add2_sep : add 2 times in same loop; separate destinations
  - add3_sep : add 3 times in same loop; separate destinations
  Note that each does some additions in a loop. Time each of these WITH
  THE SAME MULT/EXP parameters and show your timings. Describe how the
  timings compare and speculate on why.

  Note that all of these involve incrementing a counter (`i++') so the
  number of additions is one greater than the algorithm name suggests.


real	0m0.631s
user	0m0.628s
sys	0m0.000s
fanxx495@csel-kh4250-37:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add2_sep 18 27
add2_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m0.630s
user	0m0.628s
sys	0m0.000s
fanxx495@csel-kh4250-37:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add3_sep 18 27
add3_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m0.956s
user	0m0.952s
sys	0m0.004s

add1 has 2 additions, add2 has 3 additions, add3 has 4 additions. but add1 time = add2 time because it is add to 2 different register which can be performed simultaneously. for add_3, even though it is doing the additions on the seperate register, but slower. this may infer that the processor can only do 2 addition operation at the same time, but i can perform some kind of pipeline operation

(B) add2_sep / add2_same
~~~~~~~~~~~~~~~~~~~~~~~~

  Compare the source code of the two algorithms below.
  - add1_sep : add 1 times in loop
  - add2_sep : add 2 times in same loop; separate destinations
  - add2_same : add 2 times in same loop; same destinations
  Note that the only difference between the add2_X algorithms is that
  the destination for the results.

  Compare timings for these and speculate on the reasons for any
  unexpected results.

fanxx495@csel-kh4250-37:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add1_sep 18 27
add1_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m0.752s
user	0m0.748s
sys	0m0.000s
fanxx495@csel-kh4250-37:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add2_sep 18 27
add2_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m0.731s
user	0m0.728s
sys	0m0.000s
fanxx495@csel-kh4250-37:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add2_same 18 27
add2_same for 18 * 2^{27} = 2415919104 iterations... complete

real	0m1.323s
user	0m1.320s
sys	0m0.004s

add1_seq and add2_seq have almost the same cost time. but add_2 same is twice of them.
add1 time = add2 time because it is add to 2 different register which can be performed simultaneously. however, add3 do the addition on the same register.

PROBLEM 2: Multiplication
=========================

(A) add1_sep / mul1_sep
~~~~~~~~~~~~~~~~~~~~~~~

  Compare the following two algorithms.
  - add1_sep : add 1 times in loop
  - mul1_sep : multiply 1 times in loop
  Time them on the same parameters and speculate on the timing
  differences.

fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add1_sep 18 27
add1_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m0.623s
user	0m0.620s
sys	0m0.000s
fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main mul1_sep 18 27
mul1_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m1.825s
user	0m1.824s
sys	0m0.000s

multiplication may take longer time to perform


(B) mul1_sep / mul2_sep / mul3_sep
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Compare the following two algorithms.
  - mul1_sep : multiply 1 times in loop
  - mul2_sep : multiply 2 times in same loop; separate destinations
  - mul3_sep : multiply 3 times in same loop; separate destinations
  Time them on the same parameters and speculate on the timing
  differences.

fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main mul1_sep 18 27
mul1_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m1.825s
user	0m1.824s
sys	0m0.000s
fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main mul2_sep 18 27
mul2_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m1.820s
user	0m1.816s
sys	0m0.000s
fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main mul3_sep 18 27
mul3_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m1.908s
user	0m1.904s
sys	0m0.000s

the time difference is almost negligible. This is probably caused by the pipeline superscaler performance of processors that when the destinations are different, processors can do operations simultaneously

(C) mul1_sep / mul2_sep / mul2_same
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Compare the following two algorithms.
  - mul1_sep : multiply 1 times in loop
  - mul2_sep : multiply 2 times in same loop; separate destinations
  - mul2_same : multiply 2 times in same loop; same destinations
  Time them on the same parameters and speculate on the timing
  differences.

fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main mul1_sep 18 27
mul1_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m1.904s
user	0m1.900s
sys	0m0.000s
fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main mul2_sep 18 27
mul2_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m1.978s
user	0m1.976s
sys	0m0.000s
fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main mul2_same 18 27
mul2_same for 18 * 2^{27} = 2415919104 iterations... complete

real	0m3.720s
user	0m3.716s
sys	0m0.000s

mul2_same will perform multiplication on the same register and therefore, it has to wait for the last one to complete to continue.

PROBLEM 3: Combined Addition/Multiplication
===========================================

(A) add1_then_mul_sep / add2_and_mul_sep
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Compare the following two algorithms.
  - add1_then_mul_sep : add and multiply in different loops; separate
    destinations
  - add2_and_mul_sep : add twice and multiply in the same loop; separate
    destinations
  Note that each loop involves incrementing a counter so both of the
  above algorithms should do the same number of operations for N
  iterations:
  -----------------------------------------------
                      loop          total  total 
   Algorithm          incr   adds   adds   mults 
  -----------------------------------------------
   add1_then_mul_sep  2 * N  1 * N  3 * N  N     
   add2_and_mul_sep_  1 * N  2 * N  3 * N  N     
  -----------------------------------------------

  Time these algorithms on the same parameters and speculate on the
  timing differences.

  Compare the timings to your earlier results for add1_sep and mul1_sep.

fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add2_and_mul_sep 18 27
add2_and_mul_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m1.826s
user	0m1.824s
sys	0m0.000s
fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add1_then_mul_sep 18 27
add1_then_mul_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m2.438s
user	0m2.432s
sys	0m0.000s

add2_and_mul_seq are the same as mul2_sep. This is probably because the processor can perform the addition and multiplication simultaneous but the multiplication is slower than addition. 

add2_then_mul_sep is the sum of add_2 sep and mul2_sep. this is because they will take the sequential order  to perform. 

(B) add2_then_mul_sep / add2_and_mul_same
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Compare the following two algorithms.
  - add_and_mul_sep : add and multiply in the same loop; separate
    destinations
  - add_and_mul_same : add and multiply in the same loop; same
    destination
  Time them on the same parameters and speculate on the timing
  differences.

  Compare the timings to your earlier results for add1_sep and mul1_sep.


fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add2_and_mul_sep 18 27
add2_and_mul_sep for 18 * 2^{27} = 2415919104 iterations... complete

real	0m1.826s
user	0m1.824s
sys	0m0.000s
fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add2_and_mul_same 18 27
add2_and_mul_same for 18 * 2^{27} = 2415919104 iterations... complete

real	0m3.173s
user	0m3.172s
sys	0m0.000s


both of them will take the corresponding time of mul_seq time. This is because the processor can perform the addition and multiplication simultaneous but the multiplication is slower than addition. 

  Compare the following two algorithms.
  - add1_then_mul_same : add and multiply in different loops; same
    destinations
  - add2_and_mul_same : add twice and multiply in the same loop; same
    destination
  As before the operation count is the same but in this case the
  destination for adds/multiplies is the same.

  Time these algorithms on the same parameters and speculate on the
  timing differences. Compare to the results from part A where the
  destinations are distinct memory/register locations.

fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add1_then_mul_same 18 27
add1_then_mul_same for 18 * 2^{27} = 2415919104 iterations... complete

real	0m2.569s
user	0m2.564s
sys	0m0.000s
fanxx495@csel-kh4250-41:/home/fanxx495/Desktop/lab09-code $ time ./superscalar_main add2_and_mul_same 18 27
add2_and_mul_same for 18 * 2^{27} = 2415919104 iterations... complete

real	0m3.113s
user	0m3.112s
sys	0m0.000s

add1_then_mul_same is sum of add1_same + mul1_same
add1_and_mul_same is mul1_same because they can be performed simultaneously. 

